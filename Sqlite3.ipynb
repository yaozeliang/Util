{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "import sqlite3\n",
    "from copy import deepcopy\n",
    "from datetime import datetime,timedelta,date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mem_usage(df):\n",
    "    print(f\"{df.memory_usage(deep=True).sum()/1024 **2:3.2f}Mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_general_info(df):\n",
    "    name = [x for x in globals() if globals()[x] is df][0]\n",
    "    print(f\"Dataframe << {name}>>has {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    print(\"=======================================\")\n",
    "    print(\"Column Types:\\n\")\n",
    "    print(df.dtypes)\n",
    "    print(\"=======================================\")\n",
    "    print(\"Missing values per column: \")\n",
    "    percent_missing = df.isnull().sum()*100 / len(df)\n",
    "    missing_value_df = pd.DataFrame({'column_name':df.columns,'percent_missing':percent_missing})\n",
    "    missing_value_df['percent_missing'] = [\"{:.2f}%\".format(x) for x in missing_value_df['percent_missing'] ]\n",
    "    print(missing_value_df)\n",
    "    print(\"=======================================\")\n",
    "    print(f\"Memory Use: {df.memory_usage(deep=True).sum()/1024 **2:3.2f}Mb\")    \n",
    "    print(\"=======================================\")\n",
    "    print(\"Missing Values in columns: \")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_col_format(df,target_type):\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].astype(target_type)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimize_df(df):\n",
    "    df.astype({col:'category' for col in df.columns if df[col].nunique() / df[col].shape[0]<0.5})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_pickle(df,name,path=None):\n",
    "    try:\n",
    "        if path==None:\n",
    "            df.to_pickle(f\"{name}.pkl\")\n",
    "            print(f\"Dataframe saved as pickle in => {os.getcwd()}\")\n",
    "        else:\n",
    "            current_path = os.getcwd()\n",
    "            df.to_pickle(f\"{path}/{name}.pkl\")\n",
    "            print(f\"Dataframe saved as pickle in => {path}/{name}.pkl\")\n",
    "            os.chdir(current_path)\n",
    "    except:\n",
    "        print(\"Save failed. Make sure it's a dataframe or the path is correct\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle_as_df(path=None):\n",
    "    result={}\n",
    "    current_path = os.getcwd()\n",
    "    target_path = os.getcwd()\n",
    "    if path!=None:\n",
    "        target_path = path\n",
    "\n",
    "        \n",
    "    os.chdir(target_path)\n",
    "    lst = glob.glob(f\"*.pkl\")\n",
    "        \n",
    "    for p in lst:\n",
    "        name = p.split(\".\")[0]\n",
    "        result[name]=pd.read_pickle(p)\n",
    "    \n",
    "    os.chdir(current_path)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_days_ago(n=0,time_format=\"%d-%m-%Y\"):\n",
    "    time_stamp = datetime.now()-timedelta(days=n)\n",
    "    return time_stamp.strftime(time_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(extension):\n",
    "    return glob.glob(f\"*.{extension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_dir(name):\n",
    "    if os.path.isdir(name):\n",
    "        shutil.rmtree(name)\n",
    "        os.makedirs(name)\n",
    "    else:\n",
    "        os.makedirs(name)\n",
    "    os.chdir(name)\n",
    "    print(f\"Current working dir => :{os.getcwd()}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_large_csv(name,chunkSize=1000000,encoding='utf-8'):\n",
    "\n",
    "    reader = pd.read_csv(name,iterator=True,encoding=encoding)\n",
    "    chunks=[]\n",
    "    loop=True\n",
    "    while loop:\n",
    "        try:\n",
    "            chunk = reader.get_chunk(chunkSize)\n",
    "            chunks.append(chunk)\n",
    "        except StopIteration:\n",
    "            loop=False\n",
    "    df = pd.concat(chunks,ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_files(\"xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_excel(\"test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get_general_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "    \n",
    "    def __init__(self,db_name):\n",
    "        self.db_name =db_name\n",
    "        self.status=False\n",
    "        try:\n",
    "            self.connection = sqlite3.connect(self.db_name)\n",
    "            print(f\"Connected to << {self.db_name}>>\")\n",
    "            self.status = True\n",
    "        except(Exception,sqlite3.Error) as error:\n",
    "            print(\"Error while trying connect\",error)\n",
    "    \n",
    "    def close_connection(self):\n",
    "        if self.status:\n",
    "            self.connection.close()\n",
    "            print(f\"Connection for << {self.db_name} >> is closed\")\n",
    "        else:\n",
    "            print(f\"Connection for << {self.db_name} >> is already closed\")\n",
    "            \n",
    "    def read_database_version(self):\n",
    "        try:\n",
    "            cursor = self.connection.cursor()\n",
    "            cursor.execute(\"select sqlite_version();\")\n",
    "            db_version = cursor.fetchone()\n",
    "            print(f\"<< {self.db_name} >> 's version is {db_version}\")\n",
    "            \n",
    "        except(Exception,sqlite3.Error) as error:\n",
    "            print(f\"Error while getting data\",error)\n",
    "    \n",
    "    def get_table_names(self):\n",
    "        try:\n",
    "            cursor = self.connection.cursor()\n",
    "            query = cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "            records =cursor.fetchall()\n",
    "            cols = [column[0] for column in query.description]\n",
    "            cursor.close()\n",
    "        except sqlite3.Error as error:\n",
    "            print(f\"Failed to read data from sqlite table\",error)\n",
    "        results = pd.DataFrame.from_records(data=records,columns=cols).rename(columns={'name':'Table Name'})\n",
    "        return results\n",
    "    \n",
    "    def read_table(self,table_name,limit=None):\n",
    "        try:\n",
    "            if limit==None:\n",
    "                sqlite_query = f\"\"\"SELECT * from {table_name}\"\"\"\n",
    "            else:\n",
    "                sqlite_query = f\"\"\"SELECT * from {table_name} LIMIT {limit}\"\"\"\n",
    "            \n",
    "            df = pd.read_sql(sqlite_query,self.connection)\n",
    "        except sqlite3.Error as error:\n",
    "            print(\"Failed to read data from sqlite table\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_column_names_from_table(self,table_name):\n",
    "        columns_names=list()\n",
    "        try:\n",
    "            cursor =self.connection.cursor()\n",
    "            table_column_names = 'PRAGMA table_info('+table_name+');'\n",
    "            cursor.execute(table_column_names)\n",
    "            records = cursor.fetchall()\n",
    "            for name in records:\n",
    "                columns_names.append(name[1])\n",
    "            \n",
    "            cursor.close()\n",
    "        except sqlite3l.Error as error:\n",
    "            print(\"Failed to get data\",error)\n",
    "            \n",
    "        return columns_names\n",
    "    \n",
    "    def update_table_with_df(self,table_name,df,drop_duplicate=False):\n",
    "        try:\n",
    "            if table_name in list(self.get_table_names()['Table Name']):\n",
    "                print(f\"Found table <<{table_name}>> in Database <<{self.db_name}>>\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"Attention , creating new table <<{table_name}>> in Database <<{self.db_name}>> \")\n",
    "            \n",
    "            df.to_sql(name=table_name,con=self.connection,if_exists=\"append\", index=False)\n",
    "            \n",
    "            if drop_duplicate:\n",
    "                new_df = self.read_table(table_name).drop_duplicates()\n",
    "                new_df.to_sql(name=table_name,con=self.connection,if_exists=\"replace\", index=False)\n",
    "            \n",
    "            print(\"Sql insert process finished.\")\n",
    "        \n",
    "        except sqlite3.Error as error:\n",
    "            print(\"Failed to update\",error)\n",
    "            print(\"If it's a creation, be careful with columns format and value types\")\n",
    "            \n",
    "            \n",
    "    def delete_table(self,table_name):\n",
    "        try:\n",
    "            cursor =self.connection.cursor()\n",
    "            sqlite_query = f\"DROP TABLE {table_name};\"\n",
    "            cursor.execute(sqlite_query)\n",
    "            self.connection.commit()\n",
    "            cursor.close()\n",
    "            print(f\"Drop table << {table_name} >> success.\")\n",
    "            \n",
    "        except sqlite3l.Error as error:\n",
    "            print(f\"Failed to delete table <<{table_name}>>\",error)\n",
    "            \n",
    "    def back_up_to(self,dest):\n",
    "        current_path = os.getcwd()\n",
    "        os.chdir(dest)\n",
    "        new_name =\"Backup\"+datetime.now().strftime(\"%d-%m-%Y\")+self.db_name\n",
    "        bck = sqlite3.connect(new_name)\n",
    "        self.connection.backup(bck)\n",
    "        bck.close()\n",
    "        print(\"Back Up finished.\")\n",
    "        os.chdir(current_path)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
